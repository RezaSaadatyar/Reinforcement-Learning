{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*Reinforcement learning (2023-2024)*\n",
    " - Temporal Difference (TD)\n",
    " - SARSA Algorithm\n",
    " - Q-Learning Algorithm\n",
    "\n",
    "*Presented by: Reza Saadatyar*\n",
    "*E-mail: Reza.Saadatyar92@gmail.com*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Functions**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "# ================================================ Environment ========================================\n",
    "def environment (all_states, all_states_j, all_actions_k, terminal_state):\n",
    "    state1, state2 = all_states_j\n",
    "    action1, action2 = all_actions_k                            # Plane velocity in vertical and horizontal directions\n",
    "    new_state = [state1 + action1, state2 + action2]\n",
    "    if np.sum(np.all(np.equal(new_state, all_states), axis=1)): # Check new state in all states\n",
    "        if (new_state == terminal_state).all():\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = -1\n",
    "    else:\n",
    "        new_state = all_states_j\n",
    "        reward = -10\n",
    "    return new_state, reward\n",
    "# ================================================== Plot ==============================================\n",
    "def plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_State, terminal_state, Q_prediction, alpha, type, plot_gif):\n",
    "    !mkdir Images\n",
    "    if plot_gif:\n",
    "        FinalTimeStep = plan.shape[0]*plan.shape[1]\n",
    "\n",
    "    states = np.zeros((FinalTimeStep , 2), dtype=int)\n",
    "    actions = np.zeros((FinalTimeStep , 2),  dtype=int)\n",
    "    rewards = np.zeros((FinalTimeStep , 1))\n",
    "    i = 0\n",
    "    if np.size(start_State)==2:\n",
    "        states[0 , :] = start_State\n",
    "    else:\n",
    "        states[0,:]=start_State[0,0:2]\n",
    "    if dis:\n",
    "        fig, ax = plt.subplots(figsize=(4,4))\n",
    "    filenames = []\n",
    "\n",
    "    while 1:\n",
    "        if i > FinalTimeStep -2:\n",
    "            break\n",
    "        if dis:\n",
    "            plan2 = np.copy(plan)\n",
    "            plan2[states[i, 0], states[i, 1]] = 3  # 3: Change the color start state\n",
    "            plan2[terminal_state[0], terminal_state[1]] = 2  # 2: Change the color terminal state\n",
    "            ax.cla()\n",
    "            ax.imshow(plan2, cmap='winter')\n",
    "            plt.title([f\"gamma: {gamma}; alpha: {alpha}; Time Step {i}; {type}\"],fontsize=8)\n",
    "            plt.text(start_State[1] - 0.4, start_State[0], 'Start', fontsize=10, color='r', fontweight='bold')\n",
    "            plt.text(terminal_state[1] - 0.3, terminal_state[0], 'End', fontsize=10, color='r', fontweight='bold')\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            if i == 0:\n",
    "               time.sleep(1)\n",
    "            else:\n",
    "               time.sleep(0.3)\n",
    "\n",
    "            if plot_gif:\n",
    "                filename = f'Images/{i}.png'\n",
    "                filenames.append(filename)\n",
    "                plt.savefig(filename, facecolor='white', )\n",
    "\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, states[i, :]), axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        if (Q_prediction==1) and (i==0):\n",
    "            actions[i, :] = start_State[0,2:4]\n",
    "        else:\n",
    "            actions[i, :] = all_actions[Ind, :]\n",
    "\n",
    "        [states[i + 1], rewards[i + 1, :]] = environment(all_states, states[i, :], actions[i, :], terminal_state)  # Environment\n",
    "\n",
    "        if (states[i + 1, :] == terminal_state).all():\n",
    "            if dis:\n",
    "                plan2 = np.copy(plan)\n",
    "                plan2[states[i + 1, 0], states[i + 1, 1]] = 3\n",
    "                plan2[terminal_state[0], terminal_state[1]] = 2\n",
    "                plt.imshow(plan2, cmap='winter')\n",
    "                plt.title([f\"gamma: {gamma}; alpha: {alpha}; Time Step {i}; {type}\"], fontsize=8)\n",
    "                if plot_gif:\n",
    "                    filename = f'Images/{i+1}.png'\n",
    "                    filenames.append(filename)\n",
    "                    plt.savefig(filename, facecolor='white')\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    states = np.delete(states, slice(i + 2, states.shape[0]), 0)\n",
    "    rewards = (np.delete(rewards, slice(i + 2, rewards.shape[0]), 0)).flatten()\n",
    "    actions = np.delete(actions, slice(i + 2, actions.shape[0]), 0)\n",
    "\n",
    "    if plot_gif:\n",
    "        with imageio.get_writer(f\"Images/{type}; gamma({gamma}); alpha({alpha}).gif\", mode='I') as writer:    # Save gif format\n",
    "         for filename in filenames:\n",
    "             image = imageio.v2.imread(filename)\n",
    "             writer.append_data(image)\n",
    "\n",
    "    return states, rewards, actions, filenames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1e34b142410>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_q_table = 2                  # 1, 2\n",
    "if run_q_table == 1:\n",
    "    plan_size = 7\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0, 1] = 0\n",
    "    plan[1, [3, 4, 6]] = 0\n",
    "    plan[2, [0, 1, 2, 6]] = 0\n",
    "    plan[3, [4, 5]] = 0\n",
    "    plan[4, [1, 2, 3]] = 0\n",
    "    plan[5, 1] = 0\n",
    "    plan[6, 3] = 0\n",
    "else:\n",
    "    plan_size = 9\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0:2,0:2] = 0\n",
    "    plan[1:9, 4] = 0\n",
    "    plan[1 ,[3, 4, 6, 7, 8]] = 0\n",
    "    plan[2, 1] = 0\n",
    "    plan[4 ,[0, 2, 3, 4, 5, 7, 8]] = 0\n",
    "    plan[8, [2,3,5, 8]] = 0\n",
    "\n",
    "plt.imshow(plan, cmap='winter')            # 'winter', 'prism', 'spring'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [],
   "source": [
    "all_states = np.array((np.where(plan.T==1)[1], np.where(plan.T==1)[0]))\n",
    "all_states = all_states.T\n",
    "all_actions = np.array([[1, 0],[-1, 0],[0, 1],[0, -1]])       # Down(1) Up(2) Right(3) Left(4)\n",
    "start_State = [8, 0]                                          # Start point\n",
    "terminal_state = np.array([8, 7])                             # End point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TD(0) algorithm:**\n",
    "*Input: the policy* $\\pi$ *to be evaluated*\n",
    "*Algorithm parameter: step size* $\\alpha \\epsilon (0, 1]$\n",
    "*Initialize V(s), for all* $s \\epsilon S^+$, *arbitrarily expect that V(terminal)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "$A \\leftarrow$ *action given by* $\\pi$ *for S*\n",
    "*Take action A, observe R,* $S^.$\n",
    "$V(S) \\leftarrow V(S) + \\alpha[R+\\lambda V(S^.)-V(S)]$\n",
    "$S \\leftarrow S^.$\n",
    "*untile S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 500/500 [01:31<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization =======================================\n",
    "alpha = 0.1\n",
    "gamma = 0.999\n",
    "Num_epochs = 500                         # Policy evaluation\n",
    "V = np.zeros((np.size(all_states, 0)))\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    v = np.copy(V)\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        action = all_actions[np.random.randint(low=0, high=len(all_actions), size=1),:]\n",
    "        action = action.flatten()\n",
    "        [new_state, reward] = environment (all_states, state, action, terminal_state)    # Environment\n",
    "        ind = np.argmax(np.sum(np.equal(all_states, state),axis=1))\n",
    "        ind_new = np.argmax(np.sum(np.equal(all_states, new_state),axis=1))\n",
    "        V[ind] = V[ind] + alpha*(reward + gamma*V[ind_new]-V[ind])\n",
    "        state = new_state\n",
    "\n",
    "        if (state==terminal_state).all():\n",
    "            break\n",
    "    if np.linalg.norm(V-v) < 1e-2:\n",
    "        break\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "policy = np.zeros((np.size(all_states, 0), 1), dtype=int)   # Policy improvement: selection of the best action; Down(1) Up(2) Right(3) Left(4)\n",
    "for j in range(0,np.size(all_states , 0)):\n",
    "    vector = np.zeros((np.size(all_actions , 0),1))\n",
    "    for k in range(0, np.size(all_actions , 0)):\n",
    "        [new_state, reward] = environment (all_states, all_states[j,:], all_actions[k,:], terminal_state)   # Environment\n",
    "        ind = np.argmax(np.sum(np.equal( all_states, new_state),axis=1))\n",
    "        vector[k] = reward + gamma*V[ind]\n",
    "    ind = np.where(vector==np.max(vector))[0]\n",
    "    policy[j] = ind[np.random.randint(low=0, high=len(ind), size=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================== Step 4:Plot TD(0) Algorithm======================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 1                             # plot_gif = 1 : Save plots\n",
    "type = 'TD(0)'\n",
    "Q_prediction = 0\n",
    "FinalTimeStep =1000000\n",
    "[states, rewards, actions, filenames] = plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_State, terminal_state, Q_prediction, alpha, type, plot_gif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Q-Learning algorithm**\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Take action A, observe R,* $S^.$\n",
    "*Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "$Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda max_a Q(S^., a)-Q(S, A)]$\n",
    "$S \\leftarrow S^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 500/500 [00:58<00:00,  8.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization ========================================\n",
    "alpha = 0.1                # Learning rate or step size determines to what extent newly acquired information overrides old information\n",
    "gamma = 0.75                # Discount factor or gamma determines the importance of future rewards\n",
    "epsilon = 0.9\n",
    "Num_epochs = 500\n",
    "FinalTimeStep =1000000\n",
    "\n",
    "num_action = all_actions.shape[0]\n",
    "state_actionPais = np.zeros((all_states.shape[0] * all_actions.shape[0], 4), dtype=int)\n",
    "for i in range(0, all_states.shape[0]):\n",
    "    state_actionPais[num_action * i:num_action + 4 * i, :] = np.concatenate((np.tile(all_states[i, :], (4, 1)), all_actions), axis=1)\n",
    "\n",
    "counter = np.zeros((state_actionPais.shape[0], 1))\n",
    "Q = np.zeros((state_actionPais.shape[0], 1))\n",
    "policy = np.random.randint(low=0, high=all_actions.shape[0], size=all_states.shape[0])\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, state),axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        [new_state, reward] = environment (all_states, state, all_actions[Ind.item(), :], terminal_state)    # Environment\n",
    "\n",
    "        state_action = np.concatenate((state, all_actions[Ind.item(),:]), axis=0)\n",
    "        ind = np.argmax(np.sum(np.equal(state_actionPais, state_action), axis=1))\n",
    "        ind_new = np.where(np.sum(np.equal(state_actionPais[:, 0:2], new_state), axis=1) == 2)[0]\n",
    "        Q[ind] = Q[ind] + alpha*(reward + gamma*np.max(Q[ind_new])-Q[ind])\n",
    "        state = new_state\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "        policy = np.zeros((np.size(all_states, 0), 1), dtype=int)\n",
    "        for k in range(0,np.size(all_states, 0)):\n",
    "            Q_ = Q[num_action*k:num_action+4*k]\n",
    "            Ind = np.where(Q_==np.max(Q_))[0]\n",
    "            policy[k] = Ind[np.random.randint(low=0, high=len(Ind), size=1)]\n",
    "\n",
    "        if (state==terminal_state).all():\n",
    "            break\n",
    "    epsilon = epsilon*0.97"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAEFCAYAAAA7VKHIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWF0lEQVR4nO3de7zUdZ3H8ddbQBQ0vIEXUMHNRV28YKxRpB4UU/O2u7WplbfyoVbuErm52s1T6+7a1nrJysVFolWTWtTUMsUCRPchBAqJgpgKCihyrMBLGRc/+8fvd3DO6Vx+M2fmzDlf38/HYx7nN7/Ldz7zm3n/bmfmO4oIzCwd29S7ADOrLofaLDEOtVliHGqzxDjUZolxqM0SU5NQSzpX0nJJR0saLqmxFo/TVZJGSXpY0v9JOqTVtBMkzclvL0n6m3z8hpLxu5T5eA93MK1R0oQKn0dfSTfnz+WyNqZ/T1KTpPM7aGNi/pxWSvp1Pny0pE9VUlOrtg+T9JCkB/Ma++fjDu9Cm1dIeiS/HZuPu0DSvPz2sU6WPz6vaY6kqyX1aWe+dl+zCus+QdJJZS4zLf87RdIznS4QEVW/AecC5+fDw4HGWjxOFeq8E9gbGArc1cF884Ed8uGHu/B47S4LNAITKmz374Av5cM/BfZoNX3P0tekk7YqrqODNmcAf5EPv4tsZ1Kong7aHJH/3QmY2/xey//2Ax7tYNndgLnAwPz+5cBnyn3NOqlvmyquv2nl1NMdh99rgO8ASLpS0lxJ15dsfa7Lt+APSdonHzdP0uR8j3GepDskPS7p0ILT22rz2ja2xjtHxKqIWEP25vgzkvYDXo6I1/NRB+btXiVJ+TzXt7Hcn9VQMm2apJvydfH1kklnS/qFpCn5fM1HCwslnV0yrvWWfizwQD48GziidGJEvNRGfW2tj9bzNEi6Mh9eIumW/O+Zkn4m6VFJw/Lp5+fP9aE29sB/AI6TtH1EvBoRbwEXAF+QdKsyN0ialbe7c/7YMyX9PB/f4qgoIlbkg38CIh+3Mh+3Ob81HyW0Pto4Cbg5It7I718D/E0n6+LdeT0PSvpyPu68ktfng/m4aZK+A9yn7Ij1dkn35jfl485XdgT7UD69dD1+P38PTNXbR7iXd1Tbn6nmFrlka3IurbbCZHuLe/Ph08m3PsCA/O8E4F/z4aeB3YG9gLXAdsD7gW8XnP5nbbZT59y2hlvN80/AeSX3dwEETAZO7aDttp7Xw81bXuDj+fBPyY4UGoFJ+biZZBuZ5jb6Av/XwWPdCByQD58PnF3kNWmnrUbyPTXQAFyZD79csp4fI9vbfgz4PNme7+58vewC/KRVm3vkNT6br7cWe2rgFODyfPhEsjdxA/BAyfvlsnbq/QbwsVbjPg18sYPneBlwUqtxc9qZt/k1+xGwdz58GzCs5PUZBMwseW3PLFnn1+XD/w0c2vy8yY5gF+Xr4uPAROC9wH/l8/8zbRzhUmBP3Zfusy/wRD68mOzFA7hU2TlRP2BZPq4pIl4GkPRsRLwp6UVg54LT22qzLaWfkX2rnXlOITu8zRaI+F3+uD8BRpO9mdvSWQ2L8r9LgBH5cPP6eZHsjbKPpCvyNg7q4HlsIDusJf/b+XlX+Z4pWc/LIuKtfPhAYD+yN+zsthaMiLXABfmRzQ3AB1vNciBwhqTjyTZgj+Tjm9fRYuC41u1K+ltg14j4Ycm49wIfouM970tkO4TmZbYDtnQwP8BI4Ob84Gwnsg3xX0uaSLYxG1Iy76Mlw82vaVtHg0vz9bgGeDfZ++DxfNpi4H2d1NSm7rz6/TxvvzEPAZC0K9AQEUcCXyFbOdAybKXDnU7voM22/E7SMEl7Aa+2nihpD2BjRPw2vz+w5JB1HNmeB0lDWy1XpIZD87+jgJXtPNdLybbqE4D1HTyPR4Bj8+HxwIIO5m2ucWhn87TS0WuyAlgQEQ0R0UCrAEp6N0Bku5omsvfdJqB5XS4H/idf/gPAF/Pxh5b8fbZVm4cAn81vpc/pP4FzImJLPm771ofuwM/JTnUG5vcnkV1f6chysj1wA/AesnV8OdnO6TRa7hRKh9t6/7Y3bQVwcH7/ECrUbaGO7LxusaSHyN6km4DfA69LmkV2nlMNbbbZzjnkFWSHVf8LfDWf77KSN/xpwF0l8+8PLJA0l+wC24x8/K1Famjl6Hxd/DoiVrczz535408hD3U759T3AKOUXal9JCJeKj2XlPQl4AvA5yV9NV/mfyRV5fWPiCbgZ8quEcwmO7wt9QlJ8yU9SHbEdj8wLx9/PdnRzvD83HkWbx/FbZJ0H/AZssP3Ut8kOwW7X1Lza/TVfNwd+bnu9mQb30+3qncd8O9k571LgMPIjiA68iVgal7fvcAAslOnucC/0vFGt5CImA9sJ+mXZKHeVGlDtTin/giwEDi61fi+JedIl9fisbv7RnY++bUyl5kGvLuONW8DXF/vdddJjQ3k5/NdbGdSR+uabCMzHxhS7+ec19OckX8mPzcvmTYFeKizNpTP3C0kfYPsPGEL8NHItvDvOMqu/F8ZEbU4902CpAayC3Zf7sbH/HdansfeEBE/6q7Hz2v4Adm59Qbg7yPizbLb6M5Qm1nt+WOiZolxqM0SU5P/U0u7Rfa/9V5qz9fqXYFZx9avJf6woc1/19bowyfDyS5+91IXzql3BWYdm3xhu5N8+G2WGIfaLDEOtVliHGqzxDjUZolxqM0S41CbJaZQqPOv+y2X9Iza6NjOzHqOTkOdfwf5u2TfcT0IOFNSR71wmFkdFdlTH0HWlc1zEbERmE7WeYCZ9UBFQj0UWFVyf3U+rgVlfS4vlLQw67HGzOqhahfKIuLGiBgTEWNgcLWaNbMyFQn1GrL+uJoNy8eZWQ9UJNQLgP0ljZC0LXAG7XeLa2Z11ulXLyNis6SLyXqA7ANMjYgna16ZmVWk0PepI+Jesm5RzayH8yfKzBLjUJslxqE2S4xDbZYYh9osMQ61WWK68/eprVRjQ70r6JrGOTVuv6G27fd6O7Y7xXtqs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxDrVZYop0ETxV0jpJT3RHQWbWNUX21NOAE2pch5lVSaehjoi5wO+6oRYzqwKfU5slpmqhdmf+Zj2DO/M3S4wPv80SU+RfWrcBjwAjJa2W9Knal2VmlSrSmf+Z3VGImVWHD7/NEuNQmyXGoTZLjENtlhiH2iwxDrVZYmrT7/eer8GFc2rSNJBGn9DuN7tjtV4/vd3k19qd5D21WWIcarPEONRmiXGozRLjUJslxqE2S4xDbZYYh9osMQ61WWKK9Hyyt6TZkpZKelLSxO4ozMwqU+RjopuBSyLiMUk7Ao9KeiAilta4NjOrQJHO/F+KiMfy4deAZcDQWhdmZpUp65xa0nBgNDC/jWlv9/v9hw1VKs/MylU41JJ2AG4HPhcRr7ae3qLf7wGDqlmjmZWhUKgl9SML9K0RcUdtSzKzrihy9VvATcCyiLi69iWZWVcU2VOPA84CjpG0OL99qMZ1mVmFinTm/zCgbqjFzKrAnygzS4xDbZYYh9osMQ61WWIcarPEONRmialNZ/615o7ezdrlPbVZYhxqs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxRXo+2U7SryT9Ou/3+2vdUZiZVabIJ8r+BBwTEa/nfZU9LOnnETGvxrWZWQWK9HwSwOv53X75LWpZlJlVrmhvon0kLQbWAQ9EhPv9NuuhCoU6IrZExGHAMOAISaPamMf9fpv1AGVd/Y6I9cBs4ISaVGNmXVbk6vdgSTvlw9sDxwFP1bguM6tQkavfewI/kNSHbCPw44j4aW3LMrNKFbn6/TjZj+KZWS/gT5SZJcahNkuMQ22WGIfaLDEOtVliHGqzxCj7vkaVG9WYgIVVb3erWvf73dhQ2/atc93Rt3uvfp3HELGwzZ+Y9p7aLDEOtVliHGqzxDjUZolxqM0S41CbJcahNkuMQ22WmMKhzjsfXCTJHSSY9WDl7KknAstqVYiZVUfRLoKHAScBU2pbjpl1VdE99bXApcBb7c3Qot9vmqpRm5lVoEhvoicD6yLi0Y7ma9HvN4OrVqCZlafInnoccKqklcB04BhJt9S0KjOrWKehjojLI2JYRAwHzgBmRcQnal6ZmVXE/6c2S0yRzvy3iog5wJyaVGJmVeE9tVliHGqzxDjUZolxqM0S41CbJcahNktMbfr93mtkcOHkqrdrZah1n9bd0S+3tW/yhcSLy93vt9k7gUNtlhiH2iwxDrVZYhxqs8Q41GaJcajNEuNQmyWm0Pep866MXgO2AJuzfsjMrCcqp5OE8RHxSs0qMbOq8OG3WWKKhjqAmZIelXRBWzO06Pf7DxuqV6GZlaXo4fcHImKNpCHAA5Keioi5pTNExI3AjZB/ocPM6qLQnjoi1uR/1wF3AkfUsigzq1yRX+gYKGnH5mHgg8ATtS7MzCpT5PB7d+BOSc3z/zAi7qtpVWZWsU5DHRHPAYd2Qy1mVgX+l5ZZYhxqs8Q41GaJcajNEuNQmyXGoTZLjENtlhiH2iwxDrVZYhxqs8Q41GaJcajNEuNQmyXGoTZLjENtlphCoZa0k6QZkp6StEzS+2pdmJlVpmjHg9cB90XERyRtCwyoYU1m1gWdhlrSIOAo4FyAiNgIbKxtWWZWqSKH3yOAJuD7khZJmpJ3QNiC+/026xmKhLovcDhwQ0SMBt4ALms9U0TcGBFjImIMAwZVuUwzK6pIqFcDqyNifn5/BlnIzawH6jTUEbEWWCVpZD7qWGBpTasys4oVvfr9D8Ct+ZXv54DzaleSmXVFoVBHxGLAv0lt1gv4E2VmiXGozRLjUJslxqE2S4xDbZYYh9osMQ61WWIcarPEONRmiXGozRLjUJslxqE2S4xDbZYYh9osMQ61WWI6DbWkkZIWl9xelfS5bqjNzCrQaScJEbEcOAxAUh9gDXBnbcsys0qVe/h9LPBsRDxfi2LMrOvKDfUZwG21KMTMqqNwqPNOB08F/red6e7M36wHKGdPfSLwWES83NZEd+Zv1jOUE+oz8aG3WY9X9KdsBwLHAXfUthwz66qi/X6/Aexa41rMrAr8iTKzxDjUZolxqM0S41CbJcahNkuMQ22WGIfaLDFFf3T+naWxod4V9Hy1XkeNc2rbPsAVNX4MNdaw8R3bneI9tVliHGqzxDjUZolxqM0S0y0Xyj7y5ByunDWV4evXsqH/QJ4YMoIJZ3+LixbezZA31vO18edW1O6B61by0SfnMGf4YTw44rCq1mzvPPuuXM/KEde1GLd+UH92Xn9Z4Tauv/heLv7uAhpmn8OD1S6woJqHetc3NnDLHf/G07sO46KTJ7HLH1/jpKfnIYLPLLiLUU0rKwp1ny1bOKjpeRof/AGN4FBb1Tw2eg/+49JxAGzctk+dqylfzUO93+9fpP+WTbwwaAh3HnAkG7bfgavf/1G+f+dVjGpaCUA0jmfOvofy9x9tZObNX2D/364GYNGe+3PRyZNYOmQE5yy6j2l3fYMf/VUDo9atYPmu+/B3Tz0EkAX7wR/QcM41Drd1WdPggfxiwn4AbOq3DedMW8y08+7itjNGcdDSJvZ5YQONjUfz7YljIYL/vGQmn7ppEcsO3I21e+xQ5+q74Zx62eB9aRowiJN+M5/f/sdpLJh8IZ969Gfc8NensupdgwE448Nf4etHn81bEncceCQTT7yYqz7wMQ5d+yzX3vfdFu0d/8wCJr/nFG4/6EiuGfsRAGYceBRnfPgrLB28b62fjr0DHD/zWV4Z/E1eGfxN7jpt+tbx42ev4MYLDicEV132S/pt3MKpdy/n89fMY/Fhe3DzWYdwzKwVdaw8U2hPLWkScD4QwBLgvIh4s8iyr/cfwLhPXs8lj/yYE55ZwJiXnmbKPd/ixI9fxYb+A9mbJn508DEA7PnqK5zwzK9436qlbEMAcPDLz7Vob+roE7l+7IcB+FOfbZk0bwZPDBmxtQ2zrpr33qF8+crs/fT7nbfj4CXrAJj6ydF877NHcMo9T3PC/c+y+8uv0zBnJQBf/+pRzDp2P8bOW8NZtzxer9KBYr/QMRT4R2BMRIwC+pB1FVxI3y2b+c2uw7jolEsYPmk6Xzv6bABGrVtBSC3m/cf5dzBu1ZNcO/bDHHfWN1n1rsFst3lji3le3HG3rcPRcnGzqnhltwH8csJ+/HLCfjz2nr22jv/dLtsDsLlvFps+W2LrNEXz37fH1UvRc+q+wPaSNgEDgBeLPsBfrVvJD2+/kumjxvP8Trtz1PPZVmzJkP34/XbZR90+/aufsGDoAVuX2fnN1znq+cfZ+9Um1vcf2G7bzcsf+cLjnL5kFncdMI43+/UvWppZm/Z68TVOn/7E1vv9Nm1pd97Z40cw6dr5fOVf5jJy+Sucevfy7iixQ0V+dmeNpG8BLwB/BGZGxMzW80m6ALgAgEG7bx2/doddeGq3fbho4T3s+sdXWTdwJ65oOJf79z+CgZv+yMjfruJ7917HlNEf4orx53LMikWc/sRspo8az5IhI9h7w7p2a3t4n4P5xYjDOer5xzl2xSKGTfoxawYNLnslmJU6fNFapp95+9b7n7vm+HbnveeUv+TqSWP55NRF9P/TZuYetS8n/+w33VFmuxSdHC5I2hm4HTgdWE/Wmf+MiLil3WX2GhlcOLmKZXYzf6Gj/vyFjk6MIWJhmyegRa5+TwBWRERTRGwi6yb4/dUsz8yqp0ioXwDGShogSWQ/krestmWZWaU6DXVEzAdmAI+R/TtrG+DGGtdlZhUq2pn/FcAVNa7FzKrA39IyS4xDbZYYh9osMQ61WWIcarPEONRmien0Y6IVNSo1Ac+XschuwCtVL6T7uP766+3Podz6942INr/oUJNQl0vSwogYU+86KuX666+3P4dq1u/Db7PEONRmiekpoe7tnyV3/fXX259D1ervEefUZlY9PWVPbWZV4lCbJaauoZZ0gqTlkp6RVPy3TXoISXtLmi1pqaQnJU2sd02VkNRH0iJJP613LeWStJOkGZKekrRM0vvqXVM5JE3K3ztPSLpN0nZdbbNuoZbUB/gucCJwEHCmpIPqVU+FNgOXRMRBwFjgs73wOQBMpPf2ZnMdcF9EHAAcSi96Hl3tfrs99dxTHwE8ExHPRcRGYDpwWh3rKVtEvBQRj+XDr5G9oYbWt6rySBoGnARMqXct5ZI0CDgKuAkgIjZGxPq6FlW+5u63+1Jm99vtqWeohwKrSu6vppcFopSk4cBoYH6dSynXtcClwFt1rqMSI4Am4Pv56cMUSe13FN/DRMQaoLn77ZeADW11v10uXyirAkk7kHWj/LmIeLXe9RQl6WRgXUQ8Wu9aKtQXOBy4ISJGA28AvebaTN799mlkG6e9gIGSPtHVdusZ6jXA3iX3h+XjehVJ/cgCfWtE3FHveso0DjhV0kqy059jJLXbn3sPtBpYnXeOCVkHmYfXsZ5y1aT77XqGegGwv6QRkrYlu0Bwdx3rKVveZfJNwLKIuLre9ZQrIi6PiGERMZxs/c+KiC7vKbpLRKwFVkkamY86Flhax5LKVZPut2v++9TtiYjNki4G7ie76jc1Ip6sVz0VGgecBSyRtDgf98WIuLd+Jb3j/ANwa75jeA44r871FBYR8yU1d7+9GVhEFT4u6o+JmiXGF8rMEuNQmyXGoTZLjENtlhiH2iwxDrVZYhxqs8T8P9qsiGYZ7C6bAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================== Step 4:Plot Q-Learning Algorithm ==================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 1                             # plot_gif = 1 : Save plots\n",
    "type = 'Q_learning'\n",
    "Q_prediction = 0\n",
    "FinalTimeStep =1000000\n",
    "[states, rewards, actions, filenames] = plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_State, terminal_state, Q_prediction, alpha, type, plot_gif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SARSA algorithm**\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Loop for each step of episode:*\n",
    "  *Take action A, observe R,* $S^.$\n",
    "  *Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "  $Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda Q(S^., A^.)-Q(S, A)]$\n",
    "$S \\leftarrow S^.; A\\leftarrow A^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
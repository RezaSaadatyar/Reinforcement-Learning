{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*Reinforcement learning (2023-2024)*\n",
    " - Temporal Difference (TD)\n",
    " - SARSA Algorithm\n",
    " - Q-Learning Algorithm\n",
    "\n",
    "*Presented by: Reza Saadatyar*\n",
    "*E-mail: Reza.Saadatyar92@gmail.com*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Functions**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "# ================================================ Environment ========================================\n",
    "def environment (all_states, all_states_j, all_actions_k, terminal_state):\n",
    "    state1, state2 = all_states_j\n",
    "    action1, action2 = all_actions_k                            # Plane velocity in vertical and horizontal directions\n",
    "    new_state = [state1 + action1, state2 + action2]\n",
    "    if np.sum(np.all(np.equal(new_state, all_states), axis=1)): # Check new state in all states\n",
    "        if (new_state == terminal_state).all():\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = -1\n",
    "    else:\n",
    "        new_state = all_states_j\n",
    "        reward = -10\n",
    "    return new_state, reward\n",
    "# ================================================== Plot ==============================================\n",
    "def plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_state, terminal_state, Q_prediction, alpha, type, plot_gif):\n",
    "    !mkdir Images\n",
    "    if plot_gif:\n",
    "        FinalTimeStep = plan.shape[0]*plan.shape[1]\n",
    "\n",
    "    states = np.zeros((FinalTimeStep , 2), dtype=int)\n",
    "    actions = np.zeros((FinalTimeStep , 2),  dtype=int)\n",
    "    rewards = np.zeros((FinalTimeStep , 1))\n",
    "    i = 0\n",
    "    if np.size(start_state)==2:\n",
    "        states[0 , :] = start_state\n",
    "    else:\n",
    "        states[0,:]=start_state[0,0:2]\n",
    "    if dis:\n",
    "        fig, ax = plt.subplots(figsize=(4,4))\n",
    "    filenames = []\n",
    "\n",
    "    while 1:\n",
    "        if i > FinalTimeStep -2:\n",
    "            break\n",
    "        if dis:\n",
    "            plan2 = np.copy(plan)\n",
    "            plan2[states[i, 0], states[i, 1]] = 3  # 3: Change the color start state\n",
    "            plan2[terminal_state[0], terminal_state[1]] = 2  # 2: Change the color terminal state\n",
    "            ax.cla()\n",
    "            ax.imshow(plan2, cmap='winter')\n",
    "            plt.title([f\"gamma: {gamma}; alpha: {alpha}; Time Step {i}; {type}\"],fontsize=8)\n",
    "            plt.text(start_state[1] - 0.4, start_state[0], 'Start', fontsize=10, color='r', fontweight='bold')\n",
    "            plt.text(terminal_state[1] - 0.3, terminal_state[0], 'End', fontsize=10, color='r', fontweight='bold')\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            if i == 0:\n",
    "               time.sleep(1)\n",
    "            else:\n",
    "               time.sleep(0.3)\n",
    "\n",
    "            if plot_gif:\n",
    "                filename = f'Images/{i}.png'\n",
    "                filenames.append(filename)\n",
    "                plt.savefig(filename, facecolor='white', )\n",
    "\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, states[i, :]), axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        if (Q_prediction==1) and (i==0):\n",
    "            actions[i, :] = start_state[0,2:4]\n",
    "        else:\n",
    "            actions[i, :] = all_actions[Ind, :]\n",
    "\n",
    "        [states[i + 1], rewards[i + 1, :]] = environment(all_states, states[i, :], actions[i, :], terminal_state)  # Environment\n",
    "\n",
    "        if (states[i + 1, :] == terminal_state).all():\n",
    "            if dis:\n",
    "                plan2 = np.copy(plan)\n",
    "                plan2[states[i + 1, 0], states[i + 1, 1]] = 3\n",
    "                plan2[terminal_state[0], terminal_state[1]] = 2\n",
    "                plt.imshow(plan2, cmap='winter')\n",
    "                plt.title([f\"gamma: {gamma}; alpha: {alpha}; Time Step {i}; {type}\"], fontsize=8)\n",
    "                if plot_gif:\n",
    "                    filename = f'Images/{i+1}.png'\n",
    "                    filenames.append(filename)\n",
    "                    plt.savefig(filename, facecolor='white')\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "    states = np.delete(states, slice(i + 2, states.shape[0]), 0)\n",
    "    rewards = (np.delete(rewards, slice(i + 2, rewards.shape[0]), 0)).flatten()\n",
    "    actions = np.delete(actions, slice(i + 2, actions.shape[0]), 0)\n",
    "\n",
    "    if plot_gif:\n",
    "        with imageio.get_writer(f\"Images/{type}; gamma({gamma}); alpha({alpha}).gif\", mode='I') as writer:    # Save gif format\n",
    "         for filename in filenames:\n",
    "             image = imageio.v2.imread(filename)\n",
    "             writer.append_data(image)\n",
    "\n",
    "    return states, rewards, actions, filenames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1e3556d1d50>"
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_q_table = 2                  # 1, 2\n",
    "if run_q_table == 1:\n",
    "    plan_size = 7\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0, 1] = 0\n",
    "    plan[1, [3, 4, 6]] = 0\n",
    "    plan[2, [0, 1, 2, 6]] = 0\n",
    "    plan[3, [4, 5]] = 0\n",
    "    plan[4, [1, 2, 3]] = 0\n",
    "    plan[5, 1] = 0\n",
    "    plan[6, 3] = 0\n",
    "else:\n",
    "    plan_size = 9\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0:2,0:2] = 0\n",
    "    plan[1:9, 4] = 0\n",
    "    plan[1 ,[3, 4, 6, 7, 8]] = 0\n",
    "    plan[2, 1] = 0\n",
    "    plan[4 ,[0, 2, 3, 4, 5, 7, 8]] = 0\n",
    "    plan[8, [2,3,5, 8]] = 0\n",
    "\n",
    "plt.imshow(plan, cmap='winter')            # 'winter', 'prism', 'spring'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "all_states = np.array((np.where(plan.T==1)[1], np.where(plan.T==1)[0]))\n",
    "all_states = all_states.T\n",
    "all_actions = np.array([[1, 0],[-1, 0],[0, 1],[0, -1]])       # Down(1) Up(2) Right(3) Left(4)\n",
    "start_state = [8, 0]                                          # Start point\n",
    "terminal_state = np.array([8, 7])                             # End point"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TD(0) algorithm:**\n",
    "*Input: the policy* $\\pi$ *to be evaluated*\n",
    "*Algorithm parameter: step size* $\\alpha \\epsilon (0, 1]$\n",
    "*Initialize V(s), for all* $s \\epsilon S^+$, *arbitrarily expect that V(terminal)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "$A \\leftarrow$ *action given by* $\\pi$ *for S*\n",
    "*Take action A, observe R,* $S^.$\n",
    "$V(S) \\leftarrow V(S) + \\alpha[R+\\lambda V(S^.)-V(S)]$\n",
    "$S \\leftarrow S^.$\n",
    "*untile S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 500/500 [01:03<00:00,  7.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization =======================================\n",
    "alpha = 0.1\n",
    "gamma = 0.999\n",
    "Num_epochs = 500                         # Policy evaluation\n",
    "V = np.zeros((np.size(all_states, 0)))\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    v = np.copy(V)\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        action = all_actions[np.random.randint(low=0, high=len(all_actions), size=1),:]\n",
    "        action = action.flatten()\n",
    "        [new_state, reward] = environment (all_states, state, action, terminal_state)    # Environment\n",
    "        ind = np.argmax(np.sum(np.equal(all_states, state),axis=1))\n",
    "        ind_new = np.argmax(np.sum(np.equal(all_states, new_state),axis=1))\n",
    "        V[ind] = V[ind] + alpha*(reward + gamma*V[ind_new]-V[ind])\n",
    "        state = new_state\n",
    "\n",
    "        if (state==terminal_state).all():\n",
    "            break\n",
    "    if np.linalg.norm(V-v) < 1e-2:\n",
    "        break\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "policy = np.zeros((np.size(all_states, 0), 1), dtype=int)   # Policy improvement: selection of the best action; Down(1) Up(2) Right(3) Left(4)\n",
    "for j in range(0,np.size(all_states , 0)):\n",
    "    vector = np.zeros((np.size(all_actions , 0),1))\n",
    "    for k in range(0, np.size(all_actions , 0)):\n",
    "        [new_state, reward] = environment (all_states, all_states[j,:], all_actions[k,:], terminal_state)   # Environment\n",
    "        ind = np.argmax(np.sum(np.equal( all_states, new_state),axis=1))\n",
    "        vector[k] = reward + gamma*V[ind]\n",
    "    ind = np.where(vector==np.max(vector))[0]\n",
    "    policy[j] = ind[np.random.randint(low=0, high=len(ind), size=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================== Step 4:Plot TD(0) Algorithm======================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 0                             # plot_gif = 1 : Save plots\n",
    "type = 'TD(0)'\n",
    "Q_prediction = 0\n",
    "FinalTimeStep =1000000\n",
    "[states, rewards, actions, filenames] = plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_state, terminal_state, Q_prediction, alpha, type, plot_gif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Q-Learning algorithm**\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Take action A, observe R,* $S^.$\n",
    "*Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "$Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda max_a Q(S^., a)-Q(S, A)]$\n",
    "$S \\leftarrow S^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 500/500 [00:56<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization ========================================\n",
    "alpha = 0.1                # Learning rate or step size determines to what extent newly acquired information overrides old information\n",
    "gamma = 0.8                # Discount factor or gamma determines the importance of future rewards\n",
    "epsilon = 0.9\n",
    "Num_epochs = 500\n",
    "FinalTimeStep =1000000\n",
    "\n",
    "num_action = all_actions.shape[0]\n",
    "state_actionPais = np.zeros((all_states.shape[0] * all_actions.shape[0], 4), dtype=int)\n",
    "for i in range(0, all_states.shape[0]):\n",
    "    state_actionPais[num_action * i:num_action + 4 * i, :] = np.concatenate((np.tile(all_states[i, :], (4, 1)), all_actions), axis=1)\n",
    "\n",
    "counter = np.zeros((state_actionPais.shape[0], 1))\n",
    "Q = np.zeros((state_actionPais.shape[0], 1))\n",
    "policy = np.random.randint(low=0, high=all_actions.shape[0], size=all_states.shape[0])\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, state),axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        [new_state, reward] = environment (all_states, state, all_actions[Ind.item(), :], terminal_state)    # Environment\n",
    "\n",
    "        state_action = np.concatenate((state, all_actions[Ind.item(),:]), axis=0)\n",
    "        ind = np.argmax(np.sum(np.equal(state_actionPais, state_action), axis=1))\n",
    "        ind_new = np.where(np.sum(np.equal(state_actionPais[:, 0:2], new_state), axis=1) == 2)[0]\n",
    "        Q[ind] = Q[ind] + alpha*(reward + gamma*np.max(Q[ind_new])-Q[ind])\n",
    "        state = new_state\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "        policy = np.zeros((np.size(all_states, 0), 1), dtype=int)\n",
    "        for k in range(0,np.size(all_states, 0)):\n",
    "            Q_ = Q[num_action*k:num_action+4*k]\n",
    "            Ind = np.where(Q_==np.max(Q_))[0]\n",
    "            policy[k] = Ind[np.random.randint(low=0, high=len(Ind), size=1)]\n",
    "\n",
    "        if (state==terminal_state).all():\n",
    "            break\n",
    "    epsilon = epsilon*0.97"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================== Step 4:Plot Q-Learning Algorithm ==================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 1                             # plot_gif = 1 : Save plots\n",
    "type = 'Q_learning'\n",
    "Q_prediction = 0\n",
    "FinalTimeStep =1000000\n",
    "[states, rewards, actions, filenames] = plot(plan, all_states, all_actions,policy, FinalTimeStep,gamma, epsilon, dis, start_state, terminal_state, Q_prediction, alpha, type, plot_gif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SARSA algorithm**\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Loop for each step of episode:*\n",
    "  *Take action A, observe R,* $S^.$\n",
    "  *Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "  $Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda Q(S^., A^.)-Q(S, A)]$\n",
    "$S \\leftarrow S^.; A\\leftarrow A^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*Reinforcement learning (2023-2024)*\n",
    " - Tabular TD(0) for estimating $\\nu_\\pi$\n",
    " - Q-learning (off-policy TD control) for estimating $\\pi \\approx \\pi_.$\n",
    " - Sarsa (on-policy TD control) for estimating $Q \\approx q_0$\n",
    "\n",
    "\n",
    "*Presented by: Reza Saadatyar*\n",
    "*E-mail: Reza.Saadatyar92@gmail.com*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Functions**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# ================================================ Environment ========================================\n",
    "def environment (all_states, all_states_j, all_actions_k, terminal_state):\n",
    "    state1, state2 = all_states_j\n",
    "    action1, action2 = all_actions_k                            # Plane velocity in vertical and horizontal directions\n",
    "    new_state = [state1 + action1, state2 + action2]\n",
    "    if np.sum(np.all(np.equal(new_state, all_states), axis=1)): # Check new state in all states\n",
    "        if (new_state == terminal_state).all():\n",
    "            reward = 10\n",
    "        else:\n",
    "            reward = -1\n",
    "    else:\n",
    "        new_state = all_states_j\n",
    "        reward = -10\n",
    "    return new_state, reward\n",
    "# ================================================== Plot ==============================================\n",
    "def plot(plan, all_states, all_actions, policy, start_point, Num_epochs, end_point, gamma, epsilon, type, dis, plot_gif,Q_prediction):\n",
    "\n",
    "    FinalTimeStep = 1000000\n",
    "    if plot_gif:\n",
    "        FinalTimeStep = plan.shape[0]*plan.shape[1]\n",
    "\n",
    "    states = np.zeros((FinalTimeStep , 2), dtype=int)\n",
    "    actions = np.zeros((FinalTimeStep , 2),  dtype=int)\n",
    "    rewards = np.zeros((FinalTimeStep , 1))\n",
    "    states[0,:]=start_point[0:2]\n",
    "    Count = 0\n",
    "\n",
    "    if dis:\n",
    "        fig, ax = plt.subplots(figsize=(4.5,4.5))\n",
    "        !mkdir Images\n",
    "    filenames = []\n",
    "\n",
    "    while 1:\n",
    "        if Count > FinalTimeStep -2:\n",
    "            break\n",
    "        if dis:\n",
    "            plan2 = np.copy(plan)\n",
    "            plan2[states[Count, 0], states[Count, 1]] = 3  # 3: Change the color start state\n",
    "            plan2[end_point[0], end_point[1]] = 2  # 2: Change the color terminal state\n",
    "            ax.cla()\n",
    "            ax.imshow(plan2, cmap='winter')\n",
    "            plt.title([f\"gamma:{gamma}; Time Step:{Count}; Num_epochs:{Num_epochs}; {type}\"],fontsize=8)\n",
    "            plt.text(start_point[1] - 0.4, start_point[0], 'Start', fontsize=10, color='r', fontweight='bold')\n",
    "            plt.text(end_point[1] - 0.3, end_point[0], 'End', fontsize=10, color='r', fontweight='bold')\n",
    "            display(fig)\n",
    "            clear_output(wait=True)\n",
    "            if Count == 0:\n",
    "               time.sleep(1)\n",
    "            else:\n",
    "               time.sleep(0.3)\n",
    "\n",
    "            if plot_gif:\n",
    "                filename = f'Images/{Count}.png'\n",
    "                filenames.append(filename)\n",
    "                plt.savefig(filename, facecolor='white')\n",
    "\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, states[Count, :]), axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        if (Q_prediction==1) and (Count==0):\n",
    "            actions[Count, :] = start_point[2:4]\n",
    "        else:\n",
    "            actions[Count, :] = all_actions[Ind, :]\n",
    "\n",
    "        [states[Count + 1, :], rewards[Count + 1, :]] = environment(all_states, states[Count, :], actions[Count, :], end_point)  # Environment\n",
    "\n",
    "        if (states[Count + 1, :] == end_point).all():\n",
    "            if dis:\n",
    "                plan2 = np.copy(plan)\n",
    "                plan2[states[Count + 1, 0], states[Count + 1, 1]] = 3\n",
    "                plan2[end_point[0], end_point[1]] = 2\n",
    "                plt.imshow(plan2, cmap='winter')\n",
    "                plt.title([f\"gamma:{gamma}; Time Step:{Count}; Num_epochs:{Num_epochs}; {type}\"], fontsize=8)\n",
    "                if plot_gif:\n",
    "                    filename = f'Images/{Count+1}.png'\n",
    "                    filenames.append(filename)\n",
    "                    plt.savefig(filename, facecolor='white')\n",
    "            break\n",
    "        Count = Count + 1\n",
    "\n",
    "    states = np.delete(states, slice(Count + 2, states.shape[0]), 0)\n",
    "    rewards = (np.delete(rewards, slice(Count + 2, rewards.shape[0]), 0)).flatten()\n",
    "    actions = np.delete(actions, slice(Count + 2, actions.shape[0]), 0)\n",
    "\n",
    "    if plot_gif:\n",
    "        with imageio.get_writer(f\"Images/{type}; gamma({gamma}).gif\", mode='I') as writer:    # Save gif format\n",
    "         for filename in filenames:\n",
    "             image = imageio.v2.imread(filename)\n",
    "             writer.append_data(image)\n",
    "\n",
    "    return states, rewards, actions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(6.7, 8, 'End')"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_q_table = 2                 # 1, 2\n",
    "if run_q_table == 1:\n",
    "    plan_size = 7\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0, 1] = 0\n",
    "    plan[1, [3, 4, 6]] = 0\n",
    "    plan[2, [0, 1, 2, 6]] = 0\n",
    "    plan[3, [4, 5]] = 0\n",
    "    plan[4, [1, 2, 3]] = 0\n",
    "    plan[5, 1] = 0\n",
    "    plan[6, 3] = 0\n",
    "    start_point = [0, 0]                       # Start point\n",
    "    end_point = np.array([3, 6])               # End point\n",
    "else:\n",
    "    plan_size = 9\n",
    "    plan = np.ones((plan_size, plan_size))  # 1:free; 0: barrier\n",
    "    plan[0:2,0:2] = 0\n",
    "    plan[1:9, 4] = 0\n",
    "    plan[1 ,[3, 4, 6, 7, 8]] = 0\n",
    "    plan[2, 1] = 0\n",
    "    plan[4 ,[0, 2, 3, 4, 5, 7, 8]] = 0\n",
    "    plan[8, [2,3,5, 8]] = 0\n",
    "    start_point = [8, 0]                       # Start point\n",
    "    end_point = np.array([8, 7])               # End point\n",
    "\n",
    "plt.imshow(plan, cmap='winter')            # 'winter', 'prism', 'spring'\n",
    "plt.text(start_point[1] - 0.4, start_point[0], 'Start', fontsize=10, color='r', fontweight='bold')\n",
    "plt.text(end_point[1] - 0.3, end_point[0], 'End', fontsize=10, color='r', fontweight='bold')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "all_states = np.array((np.where(plan.T==1)[1], np.where(plan.T==1)[0]))\n",
    "all_states = all_states.T\n",
    "all_actions = np.array([[1, 0],[-1, 0],[0, 1],[0, -1]])       # Down(1) Up(2) Right(3) Left(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Tabular TD(0) for estimating** $\\nu_\\pi$ :\n",
    "*Input: the policy* $\\pi$ *to be evaluated*\n",
    "*Algorithm parameter: step size* $\\alpha \\epsilon (0, 1]$\n",
    "*Initialize V(s), for all* $s \\epsilon S^+$, *arbitrarily expect that V(terminal)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "$A \\leftarrow$ *action given by* $\\pi$ *for S*\n",
    "*Take action A, observe R,* $S^.$\n",
    "$V(S) \\leftarrow V(S) + \\alpha[R+\\lambda V(S^.)-V(S)]$\n",
    "$S \\leftarrow S^.$\n",
    "*untile S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 600/600 [01:11<00:00,  8.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization =======================================\n",
    "alpha = 0.1\n",
    "gamma = 0.999\n",
    "Num_epochs = 600                         # Policy evaluation\n",
    "V = np.zeros((np.size(all_states, 0)))\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    v = np.copy(V)\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        action = all_actions[np.random.randint(low=0, high=len(all_actions), size=1),:]\n",
    "        action = action.flatten()\n",
    "        [new_state, reward] = environment (all_states, state, action, end_point)    # Environment\n",
    "        ind = np.argmax(np.sum(np.equal(all_states, state),axis=1))\n",
    "        ind_new = np.argmax(np.sum(np.equal(all_states, new_state),axis=1))\n",
    "        V[ind] = V[ind] + alpha*(reward + gamma*V[ind_new]-V[ind])\n",
    "        state = new_state\n",
    "\n",
    "        if (state==end_point).all():\n",
    "            break\n",
    "    if np.linalg.norm(V-v) < 1e-2:\n",
    "        break\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "policy = np.zeros((np.size(all_states, 0), 1), dtype=int)   # Policy improvement: selection of the best action; Down(1) Up(2) Right(3) Left(4)\n",
    "for j in range(0,np.size(all_states , 0)):\n",
    "    vector = np.zeros((np.size(all_actions , 0),1))\n",
    "    for k in range(0, np.size(all_actions , 0)):\n",
    "        [new_state, reward] = environment (all_states, all_states[j,:], all_actions[k,:], end_point)   # Environment\n",
    "        ind = np.argmax(np.sum(np.equal( all_states, new_state),axis=1))\n",
    "        vector[k] = reward + gamma*V[ind]\n",
    "    ind = np.where(vector==np.max(vector))[0]\n",
    "    policy[j] = ind[np.random.randint(low=0, high=len(ind), size=1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 324x324 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================== Step 4:Plot TD(0) Algorithm======================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 0                             # plot_gif = 1 : Save plots\n",
    "type = 'TD(0)'\n",
    "\n",
    "[states, rewards, actions] = plot(plan, all_states, all_actions, policy, start_point, Num_epochs, end_point, gamma, epsilon, type, dis,  plot_gif, Q_prediction=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Q-learning (off-policy TD control) for estimating** $\\pi \\approx \\pi_.$ :\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Loop for each step of episode:*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Take action A, observe R,* $S^.$\n",
    "*Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "$Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda max_a Q(S^., a)-Q(S, A)]$\n",
    "$S \\leftarrow S^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number Epochs:: 100%|██████████| 600/600 [00:58<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== Step 1:Initialization ========================================\n",
    "alpha = 0.1                # Learning rate or step size determines to what extent newly acquired information overrides old information\n",
    "gamma = 0.6                # Discount factor or gamma determines the importance of future rewards\n",
    "epsilon = 0.9\n",
    "Num_epochs = 600\n",
    "\n",
    "num_action = all_actions.shape[0]\n",
    "state_actionPais = np.zeros((all_states.shape[0] * all_actions.shape[0], 4), dtype=int)\n",
    "for i in range(0, all_states.shape[0]):\n",
    "    state_actionPais[num_action * i:num_action + 4 * i, :] = np.concatenate((np.tile(all_states[i, :], (4, 1)), all_actions), axis=1)\n",
    "\n",
    "counter = np.zeros((state_actionPais.shape[0], 1))\n",
    "Q = np.zeros((state_actionPais.shape[0], 1))\n",
    "policy = np.random.randint(low=0, high=all_actions.shape[0], size=all_states.shape[0])\n",
    "# ====================================== Step 2:Policy Evaluation =======================================\n",
    "for i in tqdm(range(0, Num_epochs), desc='Number Epochs:'):\n",
    "    state = all_states[np.random.randint(low=0, high=len(all_states)-1, size=1),:]\n",
    "    state = state.flatten()\n",
    "    while 1:\n",
    "        if np.random.rand(1)>epsilon:\n",
    "            Ind = policy[np.argmax(np.sum(np.equal(all_states, state),axis=1))]\n",
    "        else:\n",
    "            Ind = np.random.randint(low=0, high=all_actions.shape[0], size=1)\n",
    "\n",
    "        [new_state, reward] = environment (all_states, state, all_actions[Ind.item(), :], end_point)    # Environment\n",
    "\n",
    "        state_action = np.concatenate((state, all_actions[Ind.item(),:]), axis=0)\n",
    "        ind = np.argmax(np.sum(np.equal(state_actionPais, state_action), axis=1))\n",
    "        ind_new = np.where(np.sum(np.equal(state_actionPais[:, 0:2], new_state), axis=1) == 2)[0]\n",
    "        Q[ind] = Q[ind] + alpha*(reward + gamma*np.max(Q[ind_new])-Q[ind])\n",
    "        state = new_state\n",
    "# ===================================== Step 3:Policy Improvement =======================================\n",
    "        policy = np.zeros((np.size(all_states, 0), 1), dtype=int)\n",
    "        for k in range(0,np.size(all_states, 0)):\n",
    "            Q_ = Q[num_action*k:num_action+4*k]\n",
    "            Ind = np.where(Q_==np.max(Q_))[0]\n",
    "            policy[k] = Ind[np.random.randint(low=0, high=len(Ind), size=1)]\n",
    "\n",
    "        if (state==end_point).all():\n",
    "            break\n",
    "    epsilon = epsilon*0.97"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 324x324 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================================== Step 4:Plot Q-Learning Algorithm ==================================\n",
    "dis = 1                                  # dis = 1: Show plot\n",
    "epsilon = 0\n",
    "plot_gif = 0                             # plot_gif = 1 : Save plots\n",
    "type = 'Q_learning'\n",
    "\n",
    "[states, rewards, actions] = plot(plan, all_states, all_actions, policy, start_point, Num_epochs, end_point, gamma, epsilon, type, dis,  plot_gif, Q_prediction=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Sarsa (on-policy TD control) for estimating** $Q \\approx q_0$:\n",
    "*Algorithm parameters: step size* $\\alpha \\epsilon (0, 1]$, *small* $\\epsilon > 0$\n",
    "*Initialize Q(s,a), for all* $s \\epsilon S^+, a\\epsilon A(s)$, *arbitrarily expect that Q(terminal, .)=0*\n",
    "*Loop for each episode:*\n",
    "*Initialize S*\n",
    "*Choose A from S using policy derived from Q(e.g., e-greedy)*\n",
    "*Loop for each step of episode:*\n",
    "  *Take action A, observe R,* $S^.$\n",
    "  *Choose* $A^.$ *from* $S^.$ *using policy derived from Q(e.g., e-greedy)*\n",
    "  $Q(S,A) \\leftarrow Q(S,A) + \\alpha[R+\\lambda Q(S^., A^.)-Q(S, A)]$\n",
    "$S \\leftarrow S^.; A\\leftarrow A^.$\n",
    "*until S is terminal*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}